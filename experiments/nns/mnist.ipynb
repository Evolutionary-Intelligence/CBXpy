{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b37649d-ae72-49dc-855e-5109b13d9433",
   "metadata": {},
   "outputs": [],
   "source": [
    " %load_ext autoreload\n",
    "import cbx as cbx\n",
    "from cbx.dynamics.cbo import CBO\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from cbx.noise import anisotropic_noise\n",
    "from torch.func import functional_call, stack_module_state, vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8845e-7351-4304-9494-dbd4bff98df3",
   "metadata": {},
   "source": [
    "# Load data\n",
    "We load the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97fe038d-11a6-4114-bd6a-a09e83a96c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../datasets/\"\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "train_data = torchvision.datasets.MNIST(data_path, train=True, transform=transform, download=False)\n",
    "test_data = torchvision.datasets.MNIST(data_path, train=False, transform=transform, download=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64,shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127251c4-4e88-48ae-abf0-800604ef8a25",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705a76af-42bb-4ca6-9f8c-f1f6d9dbad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Perceptron\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Perceptron().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfdd8c8c-7e42-4906-8bdb-b0f358b7bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "N = 50\n",
    "models = [Perceptron() for _ in range(N)]\n",
    "params, buffers = stack_module_state(models)\n",
    "pnames = params.keys()\n",
    "pshapes = {}\n",
    "pcuts = []\n",
    "pprop = OrderedDict()\n",
    "for p in pnames:\n",
    "    a = 0\n",
    "    if len(pprop)>0:\n",
    "        a = pprop[next(reversed(pprop))][-1]\n",
    "    pprop[p] = (params[p][0,...].shape, a, a + params[p][0,...].numel())\n",
    "    \n",
    "def flatten_parameters(params, pnames):\n",
    "    return torch.concatenate([params[pname].view(N,-1).detach() for pname in pnames], dim=-1)\n",
    "\n",
    "w = flatten_parameters(params,pnames).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5790a134-0804-4db9-adb2-2209918c02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(x, model, w, pprop):\n",
    "    params = {p: w[pprop[p][-2]:pprop[p][-1]].view(pprop[p][0]) for p in pprop}\n",
    "    return functional_call(model, (params, {}), x)\n",
    "\n",
    "def eval_models(x, model, w, pprop):\n",
    "    return vmap(eval_model, (None, None, 0, None))(x, model, w, pprop)\n",
    "\n",
    "def eval_loss(x, y, loss_fct, model, w, pprop):\n",
    "    with torch.no_grad():\n",
    "        return loss_fct(eval_model(x, model, w, pprop), y)\n",
    "    \n",
    "def eval_losses(x, y, loss_fct, model, w, pprop):\n",
    "    return vmap(eval_loss, (None, None, None, None, 0, None))(x, y, loss_fct, model, w, pprop)\n",
    "\n",
    "def eval_acc(model, w, pprop):\n",
    "    res = 0\n",
    "    num_img = 0\n",
    "    for (x,y) in iter(test_loader):\n",
    "        res += torch.sum(eval_model(x, model, w, pprop).argmax(axis=1)==y)\n",
    "        num_img += x.shape[0]\n",
    "    return res/num_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac7a15f-8445-4eb3-ad00-bfdd15e201d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class objective:\n",
    "    def __init__(self, train_loader, N, device, model, pprop):\n",
    "        self.train_loader = train_loader\n",
    "        self.data_iter = iter(train_loader)\n",
    "        self.N = N\n",
    "        self.epochs = 0\n",
    "        self.device = device   \n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "        self.model = model\n",
    "        self.pprop = pprop\n",
    "        self.set_batch()\n",
    "        \n",
    "    def __call__(self, w):   \n",
    "        return eval_losses(self.x, self.y, self.loss_fct, self.model, w[0,...], self.pprop)\n",
    "    \n",
    "    def set_batch(self,):\n",
    "        (x,y) = next(self.data_iter, (None, None))\n",
    "        if x is None:\n",
    "            self.data_iter = iter(self.train_loader)\n",
    "            (x,y) = next(self.data_iter)\n",
    "            self.epochs += 1\n",
    "        self.x = x.to(self.device)\n",
    "        self.y = y.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d7abe-c445-4c23-9efe-9fcb2830d856",
   "metadata": {},
   "source": [
    "# Set up CBX Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40c7cf2-4295-4bf3-8328-e47ba7ba16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'alpha':50.0,\n",
    "        'dt': 0.1,\n",
    "        'sigma': 0.1,\n",
    "        'lamda': 1.0,\n",
    "        'term_args':{'max_time': 20},\n",
    "        'verbosity':2,\n",
    "        'batch_args':{'batch_size':N},\n",
    "        #'batch_size': M,\n",
    "        'check_f_dims':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e32f6f7-7937-4ceb-a043-93eb8e85f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_torch(x, axis, **kwargs):\n",
    "    return torch.linalg.norm(x, dim=axis, **kwargs)  \n",
    "\n",
    "\n",
    "resamplings = [cbx.utils.resampling.loss_update_resampling(M=1, wait_thresh=40)]\n",
    "f = objective(train_loader, N, device, model, pprop)\n",
    "def cc(f, x, alpha):\n",
    "    energy = f(x) # update energy\n",
    "    weights = - alpha * energy\n",
    "    coeffs = torch.exp(weights - torch.logsumexp(weights, axis=(-1,), keepdims=True))[...,None]\n",
    "    return (x * coeffs).sum(axis=-2, keepdims=True), energy\n",
    "\n",
    "def normal_torch(mean, std, size):\n",
    "    return torch.normal(mean, std, size).to(device)\n",
    "noise = anisotropic_noise(norm = norm_torch, sampler = normal_torch)\n",
    "dyn = CBO(f, f_dim='3D', x=w[None,...], noise=noise, \n",
    "          resamplings=resamplings, \n",
    "          norm=norm_torch,\n",
    "          copy=torch.clone,\n",
    "          normal=normal_torch,\n",
    "          compute_consensus=cc,\n",
    "          **kwargs)\n",
    "sched = cbx.scheduler.multiply(factor=1.03, name='alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59d1f1-c8b7-4d97-b8f5-32d41658495f",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ed4c926-f239-42b0-93c2-fcf48171adaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m f\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdyn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     sched\u001b[38;5;241m.\u001b[39mupdate(dyn)\n\u001b[1;32m      4\u001b[0m     f\u001b[38;5;241m.\u001b[39mset_batch()\n",
      "File \u001b[0;32m~/Documents/CBXpy/cbx/dynamics/pdyn.py:289\u001b[0m, in \u001b[0;36mParticleDynamic.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_step()\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_step()\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CBXpy/cbx/dynamics/pdyn.py:840\u001b[0m, in \u001b[0;36mCBXDynamic.post_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_old, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_best_cur_particle()\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_best_particle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_particles()\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack()\n",
      "File \u001b[0;32m~/Documents/CBXpy/cbx/dynamics/pdyn.py:509\u001b[0m, in \u001b[0;36mParticleDynamic.update_best_particle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_best_particle\u001b[39m(\u001b[38;5;28mself\u001b[39m,):\n\u001b[1;32m    500\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m    Updates the best particle and best energy of the whole iteration.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_energy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_cur_energy\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_energy[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_cur_energy[idx]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/st/lib/python3.8/site-packages/torch/_tensor.py:1030\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "while f.epochs < 10:\n",
    "    dyn.step()\n",
    "    sched.update(dyn)\n",
    "    f.set_batch()\n",
    "    if dyn.it%10 == 0:\n",
    "        print('Cur Best energy: ' + str(dyn.best_cur_energy))\n",
    "        print('Best energy: ' + str(dyn.best_energy))\n",
    "        print('Alpha: ' + str(dyn.alpha))\n",
    "        print('Sigma: ' + str(dyn.sigma))\n",
    "    if e != f.epochs:\n",
    "        e = f.epochs\n",
    "        print(30*'-')\n",
    "        print('Epoch: ' +str(f.epochs))\n",
    "        print('Accuracy: ' + str(eval_acc(dyn.best_particle[None,...])))\n",
    "        print(30*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b89071a-19ea-4a9e-ba09-e866c4ac3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca32038a-df05-4707-9f22-aa7c51aafc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fe3a75-1a4c-454d-94d3-18ad353b371a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'where'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'where'"
     ]
    }
   ],
   "source": [
    "x.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf761a2e-a124-45f2-818a-16d11c797f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SuperApp (py3.11)",
   "language": "python",
   "name": "superapp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
