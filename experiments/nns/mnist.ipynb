{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b37649d-ae72-49dc-855e-5109b13d9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbx as cbx\n",
    "from cbx.dynamics.cbo import CBO\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from cbx.noise import anisotropic_noise\n",
    "from torch.func import functional_call, stack_module_state, vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8845e-7351-4304-9494-dbd4bff98df3",
   "metadata": {},
   "source": [
    "# Load data\n",
    "We load the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fe038d-11a6-4114-bd6a-a09e83a96c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load MNIST\n",
    "data_path = \"../../../datasets/\"\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "train_data = torchvision.datasets.MNIST(data_path, train=True, transform=transform, download=False)\n",
    "test_data = torchvision.datasets.MNIST(data_path, train=False, transform=transform, download=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64,shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127251c4-4e88-48ae-abf0-800604ef8a25",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705a76af-42bb-4ca6-9f8c-f1f6d9dbad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Perceptron\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Perceptron().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfdd8c8c-7e42-4906-8bdb-b0f358b7bf2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'torch.Size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pcuts)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     11\u001b[0m         a \u001b[38;5;241m=\u001b[39m pcuts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m     pcuts\u001b[38;5;241m.\u001b[39mappend(a \u001b[38;5;241m+\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_parameters\u001b[39m(params, pnames):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mconcatenate([params[pname]\u001b[38;5;241m.\u001b[39mview(N,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m pname \u001b[38;5;129;01min\u001b[39;00m pnames], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'torch.Size'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "N = 50\n",
    "models = [Perceptron() for _ in range(N)]\n",
    "params, buffers = stack_module_state(models)\n",
    "pnames = params.keys()\n",
    "pshapes = {p: params[p][0,...].shape for p in pnames}\n",
    "pcuts = []\n",
    "for p in pshapes.items():\n",
    "    a = 0\n",
    "    if len(pcuts)>0:\n",
    "        a = pcuts[-1]\n",
    "    pcuts.append(a + math.prod(p))\n",
    "def flatten_parameters(params, pnames):\n",
    "    return torch.concatenate([params[pname].view(N,-1).detach() for pname in pnames], dim=-1)\n",
    "\n",
    "x = flatten_parameters(params,pnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83b5fffb-a23e-4903-b253-42232a14582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear.weight': torch.Size([10, 784]),\n",
       " 'linear.bias': torch.Size([10]),\n",
       " 'bn.weight': torch.Size([10]),\n",
       " 'bn.bias': torch.Size([10])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5790a134-0804-4db9-adb2-2209918c02d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 7870])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_model(x, w, pshapes):\n",
    "    w = torch.tensor(w, dtype=torch.float32)\n",
    "    wcut = np.prod(wshape)\n",
    "    params = {p: w[:wcut].view(pshapes[p]) for p in pshapes.keys()} \n",
    "    return functional_call(model, (params, buffers), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5fa83e9-9c4c-40ac-83f8-790734e354c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.8989e-02,  7.2750e-03, -3.2954e-02,  ...,  3.1061e-02,\n",
       "         -1.7993e-02, -1.1871e-02],\n",
       "        [ 3.1170e-02, -2.1222e-03, -2.4572e-02,  ...,  3.1753e-02,\n",
       "         -3.1188e-02, -4.8512e-03],\n",
       "        [-2.7340e-03,  2.3394e-04,  1.0914e-02,  ..., -3.1603e-02,\n",
       "          3.3151e-02,  2.7347e-02],\n",
       "        ...,\n",
       "        [-1.9654e-02,  3.3868e-02,  2.4875e-02,  ..., -3.2911e-02,\n",
       "         -1.3968e-02, -5.1924e-04],\n",
       "        [-1.5010e-02,  2.7146e-02, -5.8646e-03,  ...,  1.0248e-03,\n",
       "          1.7836e-02, -1.7886e-02],\n",
       "        [ 3.8642e-05, -1.6629e-02,  3.5446e-02,  ..., -3.0258e-02,\n",
       "         -2.8792e-02,  3.4296e-02]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7a15f-8445-4eb3-ad00-bfdd15e201d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class objective:\n",
    "    def __init__(self, train_loader, N, wshape, bshape):\n",
    "        self.train_loader = train_loader\n",
    "        self.data_iter = iter(train_loader)\n",
    "        self.N = N\n",
    "        self.wshape = wshape\n",
    "        self.bshape = bshape\n",
    "        self.wcut = np.prod(wshape)\n",
    "        self.epochs = 0\n",
    "        \n",
    "    def __call__(self, w):\n",
    "        (x,y) = next(self.data_iter, (None, None))\n",
    "        if x is None:\n",
    "            self.data_iter = iter(self.train_loader)\n",
    "            (x,y) = next(self.data_iter)\n",
    "            self.epochs += 1\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        params = {'linear.weight': w[...,:self.wcut].view(self.N, *self.wshape),\n",
    "                  'linear.bias': w[...,self.wcut:].view(self.N,*self.bshape)} \n",
    "            \n",
    "        out = vmap(wrapper, (0, 0, None, None))(params, {}, x, y)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
